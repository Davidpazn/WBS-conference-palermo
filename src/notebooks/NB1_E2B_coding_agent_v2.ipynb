{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB1 — Minimal Coding Agent with E2B (OpenAI LLM)\n",
    "\n",
    "**Goal:** one-shot coding agent that asks OpenAI to write a small Python program, then executes it safely inside an **E2B** sandbox (Firecracker microVM). Includes a single self-heal retry if execution fails.\n",
    "\n",
    "**What you’ll see**\n",
    "1) Generate code with OpenAI’s **Responses API**\n",
    "2) Start an **E2B** sandbox and run the code with `run_code`\n",
    "3) Capture stdout/stderr, and retry once with error feedback\n",
    "\n",
    "**Why E2B?** Sandboxed execution is perfect for coding agents: it’s isolated, ephemeral, and lets the agent install packages and run arbitrary commands without touching your host.\n",
    "\n",
    "> Docs: OpenAI Responses API · E2B Quickstart / Python `run_code`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prereqs\n",
    "\n",
    "- Python ≥3.9\n",
    "- Environment variables set:\n",
    "  - `OPENAI_API_KEY`\n",
    "  - `E2B_API_KEY`\n",
    "\n",
    "*(Optional)* Create a `.env` and export from your shell, but **don’t store real secrets inside your repo**.\n",
    "\n",
    "### Install packages (run once per environment)\n",
    "We pin known-good versions. Feel free to upgrade later.\n",
    "\n",
    "```bash\n",
    "%pip install -U e2b-code-interpreter openai==1.108.1 python-dotenv>=1.0 tenacity>=8.2 pydantic>=2.7\n",
    "```\n",
    "\n",
    "If you're on corporate proxies, set `PIP_INDEX_URL` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db78762",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Imports & env checks ---\n",
    "import os, re, textwrap, json\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from openai import OpenAI\n",
    "from e2b_code_interpreter import Sandbox\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "# --- Load env from repo-local file (without clobbering OS env) ---\n",
    "from pathlib import Path\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"Install python-dotenv: pip install python-dotenv\") from e\n",
    "\n",
    "ENV_PATH = Path(os.getenv(\"NB1_ENV_PATH\", \"../infra/.env\")).resolve()\n",
    "\n",
    "if ENV_PATH.exists():\n",
    "    load_dotenv(ENV_PATH, override=False)  # keep exported OS vars authoritative\n",
    "else:\n",
    "    # Optional: keep silent in CI; or raise if you want hard fail\n",
    "    print(f\"[NB1] Note: {ENV_PATH} not found; relying on OS env only.\")\n",
    "\n",
    "\n",
    "missing = [v for v in (\"OPENAI_API_KEY\", \"E2B_API_KEY\") if not os.getenv(v)]\n",
    "if missing:\n",
    "    raise EnvironmentError(\n",
    "        f\"Set required environment variables: {missing}.\\n\"\n",
    "        \"Example (bash): export OPENAI_API_KEY=sk-...; export E2B_API_KEY=e2b_...; export OPENAI_ORGANIZATION=org-...\"\n",
    "    )\n",
    "\n",
    "MODEL = os.getenv(\"NB1_OPENAI_MODEL\", \"gpt-5-nano\")  # keep cost low; upgrade as you like\n",
    "# OPENAI_ORGANIZATION = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "OPENAI_PROJECT_ID = os.getenv(\"OPENAI_PROJECT_ID\")\n",
    "# print({\"model\": MODEL, \"org\": OPENAI_ORGANIZATION, \"project\": OPENAI_PROJECT_ID})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ffd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d51cde",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Small utilities: parse code blocks and pretty printing ---\n",
    "def extract_code_blocks(text: str, language: str = \"python\") -> str:\n",
    "    \"\"\"Return the first ```python ...``` fenced block, or raw text if none.\"\"\"\n",
    "    fence = re.compile(rf\"```{language}\\n(.*?)```\", re.DOTALL | re.IGNORECASE)\n",
    "    m = fence.search(text)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "    # try any fenced block\n",
    "    any_fence = re.compile(r\"```([\\s\\S]*?)```\", re.MULTILINE)\n",
    "    m2 = any_fence.search(text)\n",
    "    return (m2.group(1).strip() if m2 else text).strip()\n",
    "\n",
    "def summarize_execution(execution) -> dict:\n",
    "    \"\"\"Best-effort extraction of stdout/stderr/text depending on SDK version.\"\"\"\n",
    "    out = {}\n",
    "    \n",
    "    # Handle None result\n",
    "    if execution is None:\n",
    "        return {\"text\": None, \"stdout\": [], \"stderr\": []}\n",
    "    \n",
    "    # Handle E2B Code Interpreter SDK Execution objects\n",
    "    if hasattr(execution, 'logs'):\n",
    "        logs = execution.logs\n",
    "        if hasattr(logs, 'stdout'):\n",
    "            out[\"stdout\"] = logs.stdout if isinstance(logs.stdout, list) else [str(logs.stdout)]\n",
    "        if hasattr(logs, 'stderr'):\n",
    "            out[\"stderr\"] = logs.stderr if isinstance(logs.stderr, list) else [str(logs.stderr)]\n",
    "    \n",
    "    # Check for text attribute\n",
    "    if hasattr(execution, 'text'):\n",
    "        out[\"text\"] = execution.text\n",
    "    \n",
    "    # Check for direct stdout/stderr attributes (fallback)\n",
    "    if \"stdout\" not in out and hasattr(execution, 'stdout'):\n",
    "        stdout = execution.stdout\n",
    "        if isinstance(stdout, list):\n",
    "            out[\"stdout\"] = stdout\n",
    "        else:\n",
    "            out[\"stdout\"] = [str(stdout)] if stdout else []\n",
    "    \n",
    "    if \"stderr\" not in out and hasattr(execution, 'stderr'):\n",
    "        stderr = execution.stderr\n",
    "        if isinstance(stderr, list):\n",
    "            out[\"stderr\"] = stderr\n",
    "        else:\n",
    "            out[\"stderr\"] = [str(stderr)] if stderr else []\n",
    "    \n",
    "    # Check for other common attributes\n",
    "    for attr in (\"output\", \"result\"):\n",
    "        if hasattr(execution, attr):\n",
    "            out[attr] = getattr(execution, attr)\n",
    "    \n",
    "    # If we don't have stdout/stderr from above, set defaults\n",
    "    if \"stdout\" not in out:\n",
    "        out[\"stdout\"] = []\n",
    "    if \"stderr\" not in out:\n",
    "        out[\"stderr\"] = []\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d74bb",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- LLM call: OpenAI Responses API ---\n",
    "client = OpenAI() # project=OPENAI_PROJECT_ID)  # uses OPENAI_API_KEY\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a disciplined coding agent. Write a *single* runnable Python script.\\n\"\n",
    "    \"Constraints:\\n\"\n",
    "    \"- No external files; everything in one script.\\n\"\n",
    "    \"- Print clear results to stdout.\\n\"\n",
    "    \"- If tests are needed, use simple asserts in __main__ instead of pytest.\\n\"\n",
    "    \"Output strictly as a fenced code block:```python ...``` and nothing else.\"\n",
    ")\n",
    "\n",
    "def llm_generate_code(task: str) -> str:\n",
    "    \"\"\"Ask the model to produce a single Python script as a fenced block.\"\"\"\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": task},\n",
    "        ],\n",
    "    )\n",
    "    # Extract text per the Responses API object shape\n",
    "    try:\n",
    "        text = resp.output[0].content[0].text\n",
    "    except Exception:\n",
    "        # Fallback if SDK shape differs\n",
    "        text = getattr(resp, \"output_text\", str(resp))\n",
    "    return extract_code_blocks(text, language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbbb051",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- E2B execution helpers ---\n",
    "def run_in_e2b(code: str) -> dict:\n",
    "    \"\"\"Create a temporary sandbox, run the code, return logs.\"\"\"\n",
    "    # Sandbox is auto-terminated after leaving the context\n",
    "    with Sandbox.create() as sbx:\n",
    "        exec_result = sbx.run_code(code)\n",
    "        return summarize_execution(exec_result)\n",
    "\n",
    "def failed(exe_summary: dict) -> bool:\n",
    "    stderr = exe_summary.get(\"stderr\")\n",
    "    if stderr and str(stderr).strip():\n",
    "        return True\n",
    "    # fallbacks for older SDKs\n",
    "    text = exe_summary.get(\"text\")\n",
    "    if isinstance(text, str) and any(tok in text.lower() for tok in (\"traceback\", \"error\", \"exception\")):\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efdd0d3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- The simplest coding agent (one retry) ---\n",
    "def coding_agent(task: str, max_retries: int = 1) -> dict:\n",
    "    code = llm_generate_code(task)\n",
    "    first = run_in_e2b(code)\n",
    "    attempt = 0\n",
    "    while failed(first) and attempt < max_retries:\n",
    "        attempt += 1\n",
    "        feedback = (\n",
    "            \"The previous script failed. Here are the logs (trimmed).\\n\\n\"\n",
    "            f\"STDERR:\\n{str(first.get('stderr',''))[:2000]}\\n\\n\"\n",
    "            f\"TEXT:\\n{str(first.get('text',''))[:2000]}\\n\\n\"\n",
    "            \"Please FIX the bug and output ONLY a single ```python``` block containing the full corrected script.\"\n",
    "        )\n",
    "        code = llm_generate_code(task + \"\\n\\n\" + feedback)\n",
    "        first = run_in_e2b(code)\n",
    "    return {\"code\": code, \"execution\": first, \"retries\": attempt}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c863aa",
   "metadata": {},
   "source": [
    "## Demo: a tiny programming task\n",
    "We’ll ask the agent to implement a small script that:\n",
    "1) Generates the first _n_ Fibonacci numbers\n",
    "2) Prints them and their sum\n",
    "3) Asserts a couple of quick checks in `__main__`\n",
    "\n",
    "You can change the task to anything that’s safe to run in a sandbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd13654c",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TASK = (\n",
    "    \"Write a single Python script that defines a function fibonacci(n) -> list[int]\"\n",
    "    \", prints the first 10 numbers and their sum, and includes a few asserts in __main__.\"\n",
    "    \" Avoid external dependencies.\"\n",
    ")\n",
    "result = coding_agent(TASK, max_retries=1)\n",
    "print(\"\\n--- Generated Code ---\\n\")\n",
    "print(result[\"code\"])\n",
    "print(\"\\n--- Execution Summary ---\\n\")\n",
    "print(json.dumps(result[\"execution\"], indent=2, default=str))\n",
    "print({\"retries\": result[\"retries\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450c6d5",
   "metadata": {},
   "source": [
    "## Notes & Next Steps\n",
    "- **Timeout/TTL:** a default sandbox lifetime is short (minutes). For longer sessions, keep it open and reuse it.\n",
    "- **Packages:** you can install packages at runtime with `commands.run('pip install ...')` or build a custom template image.\n",
    "- **Shell commands:** prefer `sandbox.commands.run()` for bash-style steps.\n",
    "- **Iteration:** For NB2, we’ll add loop control, state tracking, and traces.\n",
    "\n",
    "**Links** *(open when connected to the internet)*:\n",
    "- OpenAI Responses API Quickstart & Reference\n",
    "- E2B Quickstart (start sandbox, env var, run code)\n",
    "- E2B Python `run_code` + commands docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf8db8",
   "metadata": {},
   "source": [
    "# Continuation — Artifacts & Sandbox Management\n",
    "\n",
    "In this section we:\n",
    "1) **Persist** a sandbox to capture multiple files/folders created by code.\n",
    "2) **List** the sandbox filesystem as a tree.\n",
    "3) **Download** artifacts preserving folder structure (either all files or a single compressed tarball).\n",
    "4) **Monitor** active sandboxes and **shut them down**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c6152",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Persistent sandbox + filesystem helpers ---\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "from e2b_code_interpreter import Sandbox\n",
    "import os, io, tarfile, time, json, shlex\n",
    "from pathlib import Path\n",
    "\n",
    "PERSIST_TIMEOUT_SECONDS = int(os.getenv(\"NB1_PERSIST_TIMEOUT\", \"600\"))  # 10 min\n",
    "\n",
    "@dataclass\n",
    "class FileEntry:\n",
    "    path: str\n",
    "    is_dir: bool\n",
    "    size: Optional[int] = None\n",
    "\n",
    "def extract_output_from_execution(execution) -> str:\n",
    "    \"\"\"Extract text output from E2B execution result.\"\"\"\n",
    "    if execution is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # The E2B SDK returns Execution objects with logs.stdout as a list\n",
    "    if hasattr(execution, 'logs') and hasattr(execution.logs, 'stdout'):\n",
    "        stdout_list = execution.logs.stdout\n",
    "        if isinstance(stdout_list, list):\n",
    "            return '\\n'.join(stdout_list)\n",
    "        else:\n",
    "            return str(stdout_list) if stdout_list else \"\"\n",
    "    \n",
    "    # Fallback checks\n",
    "    if hasattr(execution, 'text') and execution.text:\n",
    "        return execution.text\n",
    "    \n",
    "    if hasattr(execution, 'stdout'):\n",
    "        stdout = execution.stdout\n",
    "        if isinstance(stdout, list):\n",
    "            return '\\n'.join(stdout)\n",
    "        else:\n",
    "            return str(stdout) if stdout else \"\"\n",
    "    \n",
    "    return str(execution) if execution else \"\"\n",
    "\n",
    "def list_tree(sbx: Sandbox, root: str = \"/home/user\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Return a list[dict] with entries in 'root' (recursive).\n",
    "    Uses a Python script executed via run_code to walk the filesystem.\n",
    "    \"\"\"\n",
    "    # Use run_code to execute Python directly in the sandbox\n",
    "    code = f'''\n",
    "import os, json\n",
    "root = {json.dumps(root)}\n",
    "results = []\n",
    "try:\n",
    "    for dp, dns, fns in os.walk(root):\n",
    "        for name in dns:\n",
    "            p = os.path.join(dp, name)\n",
    "            try:\n",
    "                st = os.lstat(p)\n",
    "                results.append({{\"path\": p, \"type\": \"dir\", \"size\": st.st_size, \"mtime\": int(st.st_mtime)}})\n",
    "            except Exception as e:\n",
    "                results.append({{\"path\": p, \"type\": \"dir\", \"error\": str(e)}})\n",
    "        for name in fns:\n",
    "            p = os.path.join(dp, name)\n",
    "            try:\n",
    "                st = os.lstat(p)\n",
    "                results.append({{\"path\": p, \"type\": \"file\", \"size\": st.st_size, \"mtime\": int(st.st_mtime)}})\n",
    "            except Exception as e:\n",
    "                results.append({{\"path\": p, \"type\": \"file\", \"error\": str(e)}})\n",
    "    for r in results:\n",
    "        print(json.dumps(r))\n",
    "except Exception as e:\n",
    "    print(json.dumps({{\"error\": f\"Failed to walk {{root}}: {{str(e)}}\"}}))\n",
    "'''\n",
    "    result = sbx.run_code(code)\n",
    "    output = extract_output_from_execution(result)\n",
    "    \n",
    "    entries = []\n",
    "    if output:\n",
    "        for line in output.strip().split('\\n'):\n",
    "            if line.strip():\n",
    "                try:\n",
    "                    entries.append(json.loads(line.strip()))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    return entries\n",
    "\n",
    "def print_tree(entries: List[Dict[str, Any]], root: str = \"/home/user\"):\n",
    "    \"\"\"\n",
    "    Pretty-print entries from list_tree output.\n",
    "    \"\"\"\n",
    "    from os.path import relpath\n",
    "\n",
    "    for e in sorted(entries, key=lambda x: x.get(\"path\", \"\")):\n",
    "        rel = relpath(e[\"path\"], root) if e.get(\"path\") else \"?\"\n",
    "        suffix = f\"  [ERR {e.get('error')}]\" if e.get(\"error\") else \"\"\n",
    "        size_info = f\" ({e.get('size', 0)} bytes)\" if e.get('type') == 'file' else \"\"\n",
    "        print(f\"{(e.get('type') or '?'):4}  {rel}{size_info}{suffix}\")\n",
    "\n",
    "def download_all_as_tar(sbx: Sandbox, remote_root: str = \"/home/user\", local_tar_path: str = None) -> str:\n",
    "    \"\"\"Create a tar.gz in the sandbox and stream it locally. Preserves structure.\"\"\"\n",
    "    # Use a safe, writable local path in the current working directory\n",
    "    if local_tar_path is None:\n",
    "        local_tar_path = \"artifacts/e2b_demo_project.tar.gz\"\n",
    "    \n",
    "    local_tar_path = Path(local_tar_path)\n",
    "    local_tar_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create a gzip tar inside the sandbox using run_code with subprocess\n",
    "    remote_tar = \"/tmp/bundle.tar.gz\"\n",
    "    tar_code = f'''\n",
    "import subprocess\n",
    "import os\n",
    "try:\n",
    "    result = subprocess.run([\n",
    "        \"tar\", \"-czf\", \"{remote_tar}\", \n",
    "        \"-C\", \"{remote_root}\", \".\"\n",
    "    ], capture_output=True, text=True, check=True)\n",
    "    print(f\"Tar created successfully: {{result.returncode}}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Tar creation failed: {{e.stderr}}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"Error: {{str(e)}}\")\n",
    "    raise\n",
    "'''\n",
    "    tar_result = sbx.run_code(tar_code)\n",
    "    tar_output = extract_output_from_execution(tar_result)\n",
    "    print(\"Tar creation result:\", tar_output)\n",
    "\n",
    "    # Read the tar file using run_code\n",
    "    read_code = f'''\n",
    "with open(\"{remote_tar}\", \"rb\") as f:\n",
    "    import base64\n",
    "    data = f.read()\n",
    "    encoded = base64.b64encode(data).decode()\n",
    "    print(\"BASE64_START\")\n",
    "    print(encoded)\n",
    "    print(\"BASE64_END\")\n",
    "'''\n",
    "    read_result = sbx.run_code(read_code)\n",
    "    output = extract_output_from_execution(read_result)\n",
    "    \n",
    "    if not output:\n",
    "        raise RuntimeError(\"Failed to read tar data from sandbox - no output received\")\n",
    "    \n",
    "    # Extract base64 encoded data\n",
    "    lines = output.strip().split('\\n')\n",
    "    start_idx = -1\n",
    "    end_idx = -1\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip() == \"BASE64_START\":\n",
    "            start_idx = i + 1\n",
    "        elif line.strip() == \"BASE64_END\":\n",
    "            end_idx = i\n",
    "            break\n",
    "    \n",
    "    if start_idx != -1 and end_idx != -1:\n",
    "        import base64\n",
    "        encoded_data = ''.join(lines[start_idx:end_idx])\n",
    "        data = base64.b64decode(encoded_data)\n",
    "        local_tar_path.write_bytes(data)\n",
    "        return str(local_tar_path)\n",
    "    else:\n",
    "        raise RuntimeError(\"Failed to extract tar data from sandbox\")\n",
    "\n",
    "def download_folder_recursive(sbx: Sandbox, remote_root: str, local_root: str = \"artifacts/e2b_demo_project\") -> str:\n",
    "    \"\"\"Recursively mirror files from sandbox -> local path. Use when you need direct files.\n",
    "    Prefer tar for large trees.\"\"\"\n",
    "    local_root = Path(local_root)\n",
    "    local_root.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    entries = list_tree(sbx, root=remote_root)\n",
    "    for entry in entries:\n",
    "        if entry.get(\"error\"):\n",
    "            print(f\"Skipping {entry['path']} due to error: {entry['error']}\")\n",
    "            continue\n",
    "            \n",
    "        rel_path = os.path.relpath(entry[\"path\"], remote_root)\n",
    "        local_path = local_root / rel_path\n",
    "        \n",
    "        if entry[\"type\"] == \"dir\":\n",
    "            local_path.mkdir(parents=True, exist_ok=True)\n",
    "        elif entry[\"type\"] == \"file\":\n",
    "            local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            try:\n",
    "                # Read file using run_code\n",
    "                read_code = f'''\n",
    "import base64\n",
    "try:\n",
    "    with open(\"{entry[\"path\"]}\", \"rb\") as f:\n",
    "        data = f.read()\n",
    "        encoded = base64.b64encode(data).decode()\n",
    "        print(\"FILE_START\")\n",
    "        print(encoded)\n",
    "        print(\"FILE_END\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading file: {{str(e)}}\")\n",
    "'''\n",
    "                read_result = sbx.run_code(read_code)\n",
    "                output = extract_output_from_execution(read_result)\n",
    "                \n",
    "                if output:\n",
    "                    # Extract base64 encoded data\n",
    "                    lines = output.strip().split('\\n')\n",
    "                    start_idx = -1\n",
    "                    end_idx = -1\n",
    "                    for i, line in enumerate(lines):\n",
    "                        if line.strip() == \"FILE_START\":\n",
    "                            start_idx = i + 1\n",
    "                        elif line.strip() == \"FILE_END\":\n",
    "                            end_idx = i\n",
    "                            break\n",
    "                    \n",
    "                    if start_idx != -1 and end_idx != -1:\n",
    "                        import base64\n",
    "                        encoded_data = ''.join(lines[start_idx:end_idx])\n",
    "                        data = base64.b64decode(encoded_data)\n",
    "                        local_path.write_bytes(data)\n",
    "                    else:\n",
    "                        print(f\"Failed to extract data for {entry['path']}\")\n",
    "                else:\n",
    "                    print(f\"No output received for {entry['path']}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {entry['path']}: {e}\")\n",
    "    \n",
    "    return str(local_root)\n",
    "\n",
    "def new_persistent_sandbox(timeout_seconds: int = PERSIST_TIMEOUT_SECONDS) -> Sandbox:\n",
    "    sbx = Sandbox.create(timeout=timeout_seconds)\n",
    "    print({\"sandboxId\": sbx.sandbox_id, \"timeout_s\": timeout_seconds})\n",
    "    return sbx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8bfba",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Demo: create nested files, then list & download ---\n",
    "PERSIST_SBX = new_persistent_sandbox()\n",
    "\n",
    "# Generate a small project structure from code\n",
    "code = r'''\n",
    "import os, json\n",
    "base = '/home/user/demo_project'\n",
    "os.makedirs(base + '/pkg/utils', exist_ok=True)\n",
    "open(base + '/README.md', 'w').write('# Demo Project\\n')\n",
    "open(base + '/pkg/__init__.py', 'w').write('')\n",
    "open(base + '/pkg/utils/helpers.py', 'w').write('def add(a,b): return a+b\\n')\n",
    "open(base + '/main.py', 'w').write('from pkg.utils.helpers import add\\nprint(add(2,3))\\n')\n",
    "print('Wrote project to', base)\n",
    "'''\n",
    "result = PERSIST_SBX.run_code(code)\n",
    "print(\"=== Project creation result ===\")\n",
    "output = extract_output_from_execution(result)\n",
    "print(\"Code execution result:\", output)\n",
    "\n",
    "# List the created files\n",
    "entries = list_tree(PERSIST_SBX, root='/home/user')\n",
    "print(\"\\n--- File Tree ---\")\n",
    "print_tree(entries, root='/home/user')\n",
    "\n",
    "# Download: as a tarball (using relative path in current directory)\n",
    "print(\"\\n--- Downloading as tarball ---\")\n",
    "tar_path = download_all_as_tar(PERSIST_SBX, remote_root='/home/user/demo_project', local_tar_path='artifacts/e2b_demo_project.tar.gz')\n",
    "print({'tar_saved_to': tar_path})\n",
    "\n",
    "# Download: direct mirror (optional, using relative path)\n",
    "print(\"\\n--- Downloading as direct mirror ---\")\n",
    "mirror_dir = download_folder_recursive(PERSIST_SBX, remote_root='/home/user/demo_project', local_root='artifacts/e2b_demo_project_mirror')\n",
    "print({'mirrored_to': mirror_dir})\n",
    "\n",
    "# Verify the tar contents\n",
    "print(\"\\n--- Verifying tar contents ---\")\n",
    "import tarfile\n",
    "try:\n",
    "    with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "        print(\"Files in tarball:\", tar.getnames())\n",
    "except Exception as e:\n",
    "    print(f\"Error reading tar: {e}\")\n",
    "\n",
    "# List local mirror contents\n",
    "print(\"\\n--- Local mirror contents ---\")\n",
    "import os\n",
    "if os.path.exists(mirror_dir):\n",
    "    for root, dirs, files in os.walk(mirror_dir):\n",
    "        level = root.replace(mirror_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f\"{subindent}{file}\")\n",
    "else:\n",
    "    print(f\"Mirror directory not found: {mirror_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908bd1c9",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Monitor & shutdown sandboxes ---\n",
    "from e2b_code_interpreter import Sandbox\n",
    "from typing import Iterable\n",
    "\n",
    "def list_running_or_paused(limit: int = 100) -> list:\n",
    "    \"\"\"List running/paused sandboxes using E2B SDK.\"\"\"\n",
    "    try:\n",
    "        # Use E2B's list method with proper pagination\n",
    "        paginator = Sandbox.list()\n",
    "        print(f\"Paginator type: {type(paginator)}\")\n",
    "        \n",
    "        items = []\n",
    "        \n",
    "        # Check if it has nextItems method (proper E2B pagination)\n",
    "        if hasattr(paginator, 'nextItems'):\n",
    "            try:\n",
    "                # Get first page\n",
    "                first_page = paginator.nextItems()\n",
    "                items.extend(first_page)\n",
    "                print(f\"Got {len(first_page)} items from first page\")\n",
    "                \n",
    "                # Get remaining pages if hasNext is True\n",
    "                while hasattr(paginator, 'hasNext') and paginator.hasNext:\n",
    "                    next_page = paginator.nextItems()\n",
    "                    items.extend(next_page)\n",
    "                    print(f\"Got {len(next_page)} items from next page\")\n",
    "            except Exception as e:\n",
    "                print(f\"Pagination failed: {e}\")\n",
    "        \n",
    "        # Fallback: try direct iteration\n",
    "        elif hasattr(paginator, '__iter__'):\n",
    "            try:\n",
    "                items = list(paginator)\n",
    "                print(f\"Got {len(items)} items via iteration\")\n",
    "            except Exception as e:\n",
    "                print(f\"Iteration failed: {e}\")\n",
    "                \n",
    "        return items\n",
    "    except Exception as e:\n",
    "        print(f\"[list_running_or_paused] error: {e}\")\n",
    "        return []\n",
    "\n",
    "def pretty_sbx_info(items: Iterable) -> None:\n",
    "    try:\n",
    "        items_list = list(items) if hasattr(items, '__iter__') else [items]\n",
    "    except TypeError:\n",
    "        print(f\"Cannot iterate over items: {type(items)}\")\n",
    "        return\n",
    "        \n",
    "    for it in items_list:\n",
    "        if it is None:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Extract sandbox information using E2B SDK methods\n",
    "            if hasattr(it, 'get_info'):\n",
    "                # Use get_info() method if available\n",
    "                info = it.get_info()\n",
    "                print(f\"Sandbox info: {info}\")\n",
    "            else:\n",
    "                # Try direct attribute access\n",
    "                print(f\"Item type: {type(it)}\")\n",
    "                sid = getattr(it, 'sandbox_id', getattr(it, 'id', 'unknown'))\n",
    "                state = getattr(it, 'state', 'unknown')\n",
    "                metadata = getattr(it, 'metadata', {})\n",
    "                print({'sandboxId': sid, 'state': state, 'metadata': metadata})\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sandbox info: {e}, item: {it}\")\n",
    "\n",
    "def kill_by_id(sandbox_id: str) -> bool:\n",
    "    \"\"\"Kill a sandbox by its ID using E2B's static kill method.\"\"\"\n",
    "    try:\n",
    "        return Sandbox.kill(sandbox_id)\n",
    "    except Exception as e:\n",
    "        print(f\"[kill_by_id] error: {e}\")\n",
    "        return False\n",
    "\n",
    "def kill_all_running() -> None:\n",
    "    \"\"\"Kill all running sandboxes.\"\"\"\n",
    "    items = list_running_or_paused()\n",
    "    for it in items:\n",
    "        if it is None:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Try to get sandbox ID\n",
    "            sid = getattr(it, 'sandbox_id', getattr(it, 'id', None))\n",
    "            if not sid:\n",
    "                print(f\"No sandbox ID found for item: {it}\")\n",
    "                continue\n",
    "                \n",
    "            ok = Sandbox.kill(sid)\n",
    "            print({'killed': sid, 'ok': ok})\n",
    "        except Exception as e:\n",
    "            print({'killed': getattr(it, 'sandbox_id', 'unknown'), 'ok': False, 'error': str(e)})\n",
    "\n",
    "# Check if we have an active sandbox first\n",
    "print(\"=== Current sandbox status ===\")\n",
    "if 'PERSIST_SBX' in locals():\n",
    "    print(f\"PERSIST_SBX type: {type(PERSIST_SBX)}\")\n",
    "    if hasattr(PERSIST_SBX, 'sandbox_id'):\n",
    "        print(f\"Sandbox ID: {PERSIST_SBX.sandbox_id}\")\n",
    "    \n",
    "    # Test if sandbox is still active by running a simple command\n",
    "    try:\n",
    "        test_result = PERSIST_SBX.run_code('print(\"Sandbox is alive!\")')\n",
    "        if test_result:\n",
    "            output = extract_output_from_execution(test_result)\n",
    "            print(f\"Sandbox test result: {output}\")\n",
    "        else:\n",
    "            print(\"Sandbox test returned None - may be terminated\")\n",
    "    except Exception as e:\n",
    "        print(f\"Sandbox test failed: {e}\")\n",
    "        \n",
    "    # Try to get sandbox info\n",
    "    try:\n",
    "        if hasattr(PERSIST_SBX, 'get_info'):\n",
    "            info = PERSIST_SBX.get_info()\n",
    "            print(f\"Sandbox info: {info}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get sandbox info: {e}\")\n",
    "\n",
    "# Show currently running/paused sandboxes\n",
    "print(\"\\n=== Listing all sandboxes ===\")\n",
    "try:\n",
    "    items = list_running_or_paused()\n",
    "    print(f\"Found {len(items)} sandboxes\")\n",
    "    if items:\n",
    "        pretty_sbx_info(items)\n",
    "    else:\n",
    "        print(\"No sandboxes found - they may have auto-terminated after timeout\")\n",
    "except Exception as e:\n",
    "    print(f\"Error listing sandboxes: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3419206d",
   "metadata": {},
   "source": [
    "### Usage tips\n",
    "- Prefer **tar download** for large/many files; it’s faster and preserves structure.\n",
    "- You can **pause** long-lived sandboxes and resume later (beta). While paused, files and memory persist. See E2B docs.\n",
    "- To **shut down**: `kill_by_id('<sandbox_id>')` or `kill_all_running()`.\n",
    "- If you used `with Sandbox.create() as sbx: ...`, that sandbox auto-terminates at the end of the context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ny3fvvvnekf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cleanup and close the persistent sandbox ---\n",
    "if 'PERSIST_SBX' in locals():\n",
    "    try:\n",
    "        # E2B uses kill() method to terminate sandboxes\n",
    "        PERSIST_SBX.kill()\n",
    "        print(\"Sandbox terminated successfully with kill()\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error terminating sandbox: {e}\")\n",
    "        # Print available methods for debugging\n",
    "        print(f\"Available methods: {[method for method in dir(PERSIST_SBX) if not method.startswith('_')]}\")\n",
    "else:\n",
    "    print(\"No persistent sandbox to close\")"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "date": "2025-09-20T19:09:30.662112",
    "name": "ChatGPT (NB1 generator)"
   }
  ],
  "colab": {
   "name": "NB1_E2B_coding_agent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai-agents-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
